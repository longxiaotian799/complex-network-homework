{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "G = nx.readedgelist('email.txt', create_using = nx.Graph(), nodetype = int)\n",
    "adj = nx.to_numpy_array(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess the email dataset\n",
    "# data = pd.read_csv(\"email.csv\", sep=r'\\s*,\\s*|[\\t]', engine='python', names=['source', 'target'])\n",
    "# data['source'] = data['source'].astype(int)\n",
    "# data['target'] = data['target'].astype(int)\n",
    "\n",
    "data = pd.read_csv('email.txt', sep=' ', names=['source', 'target', 'label'])\n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create a graph using NetworkX\n",
    "G = nx.from_pandas_edgelist(train_data, source='source', target='target')\n",
    "\n",
    "# Link prediction algorithms\n",
    "algorithms = {\n",
    "    'Katz': nx.katz_centrality_numpy,\n",
    "    'CN': nx.common_neighbors,\n",
    "    'AA': nx.adamic_adar_index,\n",
    "    'RA': nx.resource_allocation_index,\n",
    "    'LP': nx.preferential_attachment,\n",
    "    'ACT': nx.cn_soundarajan_hopcroft,\n",
    "    'SimRank': nx.simrank_similarity\n",
    "}\n",
    "# # Calculate AUC and Precision@L\n",
    "# for name, algo in algorithms.items():\n",
    "#     preds = list(algo(G))\n",
    "\n",
    "#     # Ensure the preds are in the format [(source, target, score), ...]\n",
    "#     if len(preds[0]) == 2:\n",
    "#         preds = [(u, v, s) for (u, v), s in preds]\n",
    "#     elif len(preds[0]) == 1:\n",
    "#         preds = [(u, v, s) for ((u, v), s) in preds]\n",
    "\n",
    "#     preds_df = pd.DataFrame(preds, columns=['source', 'target', 'score'])\n",
    "#     test_preds = test_data.merge(preds_df, on=['source', 'target'], how='left')\n",
    "#     test_preds['score'] = test_preds['score'].fillna(0)\n",
    "\n",
    "#     auc = roc_auc_score(test_preds['label'], test_preds['score'])\n",
    "#     precision_at_100 = precision_score(test_preds['label'], test_preds['score'], k=100)\n",
    "#     precision_at_200 = precision_score(test_preds['label'], test_preds['score'], k=200)\n",
    "\n",
    "#     print(f\"{name}: AUC={auc:.4f}, Precision@100={precision_at_100:.4f}, Precision@200={precision_at_200:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate AUC and Precision@L\n",
    "# for name, algo in algorithms.items():\n",
    "#     if name in {'CN', 'AA', 'RA', 'LP', 'ACT'}:\n",
    "#         preds = list(algo(G))\n",
    "#         preds = [(u, v, s) for (u, v, s) in preds]\n",
    "#     elif name == 'Katz':\n",
    "#         centrality = algo(G)\n",
    "#         preds = [(u, v, centrality[u] * centrality[v]) for (u, v) in nx.non_edges(G)]\n",
    "#     elif name == 'SimRank':\n",
    "#         similarity_matrix = algo(G)\n",
    "#         preds = [(u, v, similarity_matrix[u][v]) for (u, v) in nx.non_edges(G)]\n",
    "\n",
    "#     preds_df = pd.DataFrame(preds, columns=['source', 'target', 'score'])\n",
    "#     test_preds = test_data.merge(preds_df, on=['source', 'target'], how='left')\n",
    "#     test_preds['score'] = test_preds['score'].fillna(0)\n",
    "\n",
    "#     auc = roc_auc_score(test_preds['label'], test_preds['score'])\n",
    "#     precision_at_100 = precision_score(test_preds['label'], test_preds['score'], k=100)\n",
    "#     precision_at_200 = precision_score(test_preds['label'], test_preds['score'], k=200)\n",
    "\n",
    "#     print(f\"{name}: AUC={auc:.4f}, Precision@100={precision_at_100:.4f}, Precision@200={precision_at_200:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mKatz\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      7\u001b[0m     centrality \u001b[39m=\u001b[39m algo(G)\n\u001b[1;32m----> 8\u001b[0m     preds \u001b[39m=\u001b[39m [(\u001b[39mint\u001b[39;49m(u), \u001b[39mint\u001b[39;49m(v), centrality[u] \u001b[39m*\u001b[39;49m centrality[v]) \u001b[39mfor\u001b[39;49;00m (u, v) \u001b[39min\u001b[39;49;00m nx\u001b[39m.\u001b[39;49mnon_edges(G)]\n\u001b[0;32m      9\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSimRank\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     10\u001b[0m     similarity_matrix \u001b[39m=\u001b[39m algo(G)\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mKatz\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      7\u001b[0m     centrality \u001b[39m=\u001b[39m algo(G)\n\u001b[1;32m----> 8\u001b[0m     preds \u001b[39m=\u001b[39m [(\u001b[39mint\u001b[39;49m(u), \u001b[39mint\u001b[39m(v), centrality[u] \u001b[39m*\u001b[39m centrality[v]) \u001b[39mfor\u001b[39;00m (u, v) \u001b[39min\u001b[39;00m nx\u001b[39m.\u001b[39mnon_edges(G)]\n\u001b[0;32m      9\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSimRank\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     10\u001b[0m     similarity_matrix \u001b[39m=\u001b[39m algo(G)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# # Calculate AUC and Precision@L\n",
    "# for name, algo in algorithms.items():\n",
    "#     if name in {'CN', 'AA', 'RA', 'LP', 'ACT'}:\n",
    "#         preds = list(algo(G))\n",
    "#         preds = [(int(u), int(v), s) for (u, v, s) in preds]\n",
    "#     elif name == 'Katz':\n",
    "#         centrality = algo(G)\n",
    "#         preds = [(int(u), int(v), centrality[u] * centrality[v]) for (u, v) in nx.non_edges(G)]\n",
    "#     elif name == 'SimRank':\n",
    "#         similarity_matrix = algo(G)\n",
    "#         preds = [(int(u), int(v), similarity_matrix[u][v]) for (u, v) in nx.non_edges(G)]\n",
    "\n",
    "#     preds_df = pd.DataFrame(preds, columns=['source', 'target', 'score'])\n",
    "#     test_preds = test_data.merge(preds_df, on=['source', 'target'], how='left')\n",
    "#     test_preds['score'] = test_preds['score'].fillna(0)\n",
    "\n",
    "#     auc = roc_auc_score(test_preds['label'], test_preds['score'])\n",
    "#     precision_at_100 = precision_score(test_preds['label'], test_preds['score'], k=100)\n",
    "#     precision_at_200 = precision_score(test_preds['label'], test_preds['score'], k=200)\n",
    "\n",
    "#     print(f\"{name}: AUC={auc:.4f}, Precision@100={precision_at_100:.4f}, Precision@200={precision_at_200:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m roc_auc_aa \u001b[39m=\u001b[39m roc_auc_score(labels_train, [s \u001b[39mfor\u001b[39;00m u,v,s \u001b[39min\u001b[39;00m aa_scores])\n\u001b[0;32m     39\u001b[0m \u001b[39m# Compute Precision scores\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m precision_cn \u001b[39m=\u001b[39m precision_score(labels_train, [s \u001b[39mfor\u001b[39;49;00m u,v,s \u001b[39min\u001b[39;49;00m cn_scores])\n\u001b[0;32m     41\u001b[0m precision_ra \u001b[39m=\u001b[39m precision_score(labels_train, [s \u001b[39mfor\u001b[39;00m u,v,s \u001b[39min\u001b[39;00m ra_scores])\n\u001b[0;32m     42\u001b[0m precision_aa \u001b[39m=\u001b[39m precision_score(labels_train, [s \u001b[39mfor\u001b[39;00m u,v,s \u001b[39min\u001b[39;00m aa_scores])\n",
      "File \u001b[1;32mc:\\Users\\zhangwentao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[0;32m   1826\u001b[0m     y_true,\n\u001b[0;32m   1827\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1834\u001b[0m ):\n\u001b[0;32m   1835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1836\u001b[0m \n\u001b[0;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1955\u001b[0m         y_true,\n\u001b[0;32m   1956\u001b[0m         y_pred,\n\u001b[0;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1963\u001b[0m     )\n\u001b[0;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\zhangwentao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zhangwentao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1391\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1389\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1390\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1393\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1394\u001b[0m         )\n\u001b[0;32m   1395\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   1396\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1401\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1402\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.link_prediction import resource_allocation_index, adamic_adar_index\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "\n",
    "def common_neighbors(G, ebunch=None):\n",
    "    if ebunch is None:\n",
    "        ebunch = nx.non_edges(G)\n",
    "    return [(u, v, len(list(nx.common_neighbors(G, u, v)))) for u, v in ebunch]\n",
    "\n",
    "# Load the Karate dataset\n",
    "G = nx.read_edgelist('email.txt', nodetype=int, data=(('weight',int),), create_using=nx.Graph())\n",
    "\n",
    "# Generate non-existent edges (negative samples)\n",
    "non_edges = list(nx.non_edges(G))\n",
    "\n",
    "# Generate existent edges (positive samples)\n",
    "edges = list(G.edges())\n",
    "\n",
    "# Labels for the edges: 1 for existent, 0 for non-existent\n",
    "edge_labels = [1]*len(edges) + [0]*len(non_edges)\n",
    "\n",
    "# Concatenate the edge and non-edge lists\n",
    "edge_list = edges + non_edges\n",
    "\n",
    "# Split the edges into train and test sets\n",
    "edge_train, edge_test, labels_train, labels_test = train_test_split(edge_list, edge_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train the link prediction models\n",
    "cn_scores = common_neighbors(G, edge_train)\n",
    "ra_scores = list(resource_allocation_index(G, edge_train))\n",
    "aa_scores = list(adamic_adar_index(G, edge_train))\n",
    "\n",
    "# Compute the ROC AUC scores\n",
    "roc_auc_cn = roc_auc_score(labels_train, [s for u,v,s in cn_scores])\n",
    "roc_auc_ra = roc_auc_score(labels_train, [s for u,v,s in ra_scores])\n",
    "roc_auc_aa = roc_auc_score(labels_train, [s for u,v,s in aa_scores])\n",
    "\n",
    "# Compute Precision scores\n",
    "precision_cn = precision_score(labels_train, [s for u,v,s in cn_scores])\n",
    "precision_ra = precision_score(labels_train, [s for u,v,s in ra_scores])\n",
    "precision_aa = precision_score(labels_train, [s for u,v,s in aa_scores])\n",
    "\n",
    "# Print the ROC AUC and Precision scores\n",
    "print(\"ROC AUC Scores:\")\n",
    "print(f\"Common Neighbors: {roc_auc_cn}\")\n",
    "print(f\"Resource Allocation: {roc_auc_ra}\")\n",
    "print(f\"Adamic Adar: {roc_auc_aa}\")\n",
    "\n",
    "print(\"\\nPrecision Scores:\")\n",
    "print(f\"Common Neighbors: {precision_cn}\")\n",
    "print(f\"Resource Allocation: {precision_ra}\")\n",
    "print(f\"Adamic Adar: {precision_aa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m non_edges_train \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(nx\u001b[39m.\u001b[39mnon_edges(G_train))\n\u001b[0;32m     24\u001b[0m \u001b[39m# List of non-edges for testing\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m non_edges_test \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m nx\u001b[39m.\u001b[39;49mnon_edges(G) \u001b[39mif\u001b[39;49;00m e \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m non_edges_train]\n\u001b[0;32m     27\u001b[0m \u001b[39m# Local Path\u001b[39;00m\n\u001b[0;32m     28\u001b[0m lp_index \u001b[39m=\u001b[39m local_path_index(G_train, alpha\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m non_edges_train \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(nx\u001b[39m.\u001b[39mnon_edges(G_train))\n\u001b[0;32m     24\u001b[0m \u001b[39m# List of non-edges for testing\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m non_edges_test \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m nx\u001b[39m.\u001b[39mnon_edges(G) \u001b[39mif\u001b[39;00m e \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m non_edges_train]\n\u001b[0;32m     27\u001b[0m \u001b[39m# Local Path\u001b[39;00m\n\u001b[0;32m     28\u001b[0m lp_index \u001b[39m=\u001b[39m local_path_index(G_train, alpha\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhangwentao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\networkx\\classes\\function.py:915\u001b[0m, in \u001b[0;36mnon_edges\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m    913\u001b[0m u \u001b[39m=\u001b[39m nodes\u001b[39m.\u001b[39mpop()\n\u001b[0;32m    914\u001b[0m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m nodes \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(graph[u]):\n\u001b[1;32m--> 915\u001b[0m     \u001b[39myield\u001b[39;00m (u, v)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def local_path_index(G, alpha=0.1):\n",
    "    A = nx.to_numpy_array(G)\n",
    "    I = np.eye(*A.shape)\n",
    "    A_exp = np.linalg.inv(I - alpha * A) - I\n",
    "    return {(i, j): A_exp[i, j] for i in range(A.shape[0]) for j in range(i + 1, A.shape[1])}\n",
    "\n",
    "G = nx.read_edgelist('email.txt', nodetype=int, data=(('weight',int),), create_using=nx.Graph())\n",
    "\n",
    "# Split edges into train and test sets\n",
    "edges_train, edges_test = train_test_split(list(G.edges), test_size=0.1)\n",
    "\n",
    "# Create train graph\n",
    "G_train = G.copy()\n",
    "G_train.remove_edges_from(edges_test)\n",
    "\n",
    "# List of non-edges for training\n",
    "non_edges_train = list(nx.non_edges(G_train))\n",
    "\n",
    "# List of non-edges for testing\n",
    "non_edges_test = [e for e in nx.non_edges(G) if e not in non_edges_train]\n",
    "\n",
    "# Local Path\n",
    "lp_index = local_path_index(G_train, alpha=0.1)\n",
    "scores_lp = []\n",
    "labels_lp = []\n",
    "for (u, v), p in lp_index.items():\n",
    "    if (u, v) in edges_test or (v, u) in edges_test:\n",
    "        scores_lp.append(p)\n",
    "        labels_lp.append(1)\n",
    "    elif (u, v) in non_edges_test or (v, u) in non_edges_test:\n",
    "        scores_lp.append(p)\n",
    "        labels_lp.append(0)\n",
    "auc_lp = roc_auc_score(labels_lp, scores_lp)\n",
    "precision_lp = precision_score(labels_lp, [1 if x >= 0.5 else 0 for x in scores_lp])\n",
    "\n",
    "# Print results\n",
    "print(f\"Local Path: AUC = {auc_lp}, Precision = {precision_lp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 读取 email.txt 文件并解析边数据\n",
    "edges = []\n",
    "with open(\"email.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        source, target = line.strip().split()\n",
    "        edges.append((int(source), int(target)))\n",
    "\n",
    "# 将边数据打乱顺序\n",
    "np.random.shuffle(edges)\n",
    "\n",
    "# 计算选择的边数量\n",
    "num_edges = len(edges)\n",
    "num_train = int(0.9 * num_edges)\n",
    "num_test = num_edges - num_train\n",
    "\n",
    "# 分割为训练集和测试集\n",
    "train_edges = edges[:num_train]\n",
    "test_edges = edges[num_train:]\n",
    "\n",
    "# 写入 train.txt 文件\n",
    "with open(\"train.txt\", \"w\") as file:\n",
    "    for edge in train_edges:\n",
    "        file.write(f\"{edge[0]}\\t{edge[1]}\\n\")\n",
    "\n",
    "# 写入 test.txt 文件\n",
    "with open(\"test.txt\", \"w\") as file:\n",
    "    for edge in test_edges:\n",
    "        file.write(f\"{edge[0]}\\t{edge[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Link Prediction start:\n",
      "\n",
      "DataShape......\n",
      "    数据集长度：4905\n",
      "    第一列节点长度：(1104)\n",
      "    第二列节点长度：(745)\n",
      "    节点数量为：1134\n",
      "    数据集长度：546\n",
      "    第一列节点长度：(402)\n",
      "    第二列节点长度：(306)\n",
      "    节点数量为：1115\n",
      "----------SIM----------计算相似性矩阵1 7----------SIM----------\n",
      "----------Cn----------\n",
      "    SimilarityTime: 0.0299201999878278 s\n",
      "Precision@100: 0.000000\n",
      "Precision@200: 0.040000\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.8456082688875669\n",
      "    AUCTime：1.1030409336090088 s\n",
      "----------RA----------\n",
      "    SimilarityTime: 0.046875 s\n",
      "Precision@100: 0.000000\n",
      "Precision@200: 0.010000\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.8466775728732897\n",
      "    AUCTime：1.197509527206421 s\n",
      "----------Katz----------\n",
      "    SimilarityTime: 0.156250 s\n",
      "Precision@100: 1.000000\n",
      "Precision@200: 1.000000\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.8942050862581796\n",
      "    AUCTime：1.2135722637176514 s\n",
      "----------SIM----------基于随机游走----------SIM----------\n",
      "----------ACT----------\n",
      "    SimilarityTime: 1.2018004999990808 s\n",
      "Precision@100: 0.000000\n",
      "Precision@200: 0.000000\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.7885023795359904\n",
      "    AUCTime：1.2042524814605713 s\n",
      "----------AA----------\n",
      "SimilarityTime: 0.125000 s\n",
      "Precision@100: 0.000000\n",
      "Precision@200: 0.000000\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.8473564842355741\n",
      "    AUCTime：1.2051715850830078 s\n",
      "----------SIM----------基于路径----------SIM----------\n",
      "----------LP----------\n",
      "    SimilarityTime: 0.265625 s\n",
      "Precision@100: 0.700000\n",
      "Precision@200: 0.650000\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.8408491969066032\n",
      "    AUCTime：1.195260763168335 s\n",
      "----------汇总----------\n",
      "All SimilarityTime: 9.438811302185059 s\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.8405956276026175\n",
      "    AUCTime：1.1405270099639893 s\n",
      "\n",
      "RunTime: 10.601370096206665 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import Initialize\n",
    "import Evaluation_Indicators.AUC\n",
    "import similarity_indicators.CommonNeighbor\n",
    "import similarity_indicators.AA\n",
    "import similarity_indicators.RA\n",
    "import similarity_indicators.LP\n",
    "import similarity_indicators.Katz\n",
    "import similarity_indicators.ACT\n",
    "\n",
    "startTime = time.time()\n",
    "NetFile = 'Data/Email.txt'\n",
    "NetName = 'Email'\n",
    "\n",
    "print(\"\\nLink Prediction start:\\n\")\n",
    "TrainFile_Path = 'Data\\\\'+NetName+'\\\\Train.txt'\n",
    "if os.path.exists(TrainFile_Path):\n",
    "    Train_File = 'Data\\\\'+NetName+'\\\\Train.txt'\n",
    "    Test_File = 'Data\\\\'+NetName+'\\\\Test.txt'\n",
    "    MatrixAdjacency_Train, MatrixAdjacency_Test, MaxNodeNum = Initialize.Init2(Test_File, Train_File)\n",
    "else:\n",
    "    MatrixAdjacency_Net, MaxNodeNum = Initialize.Init(NetFile)\n",
    "    MatrixAdjacency_Train, MatrixAdjacency_Test = Initialize.Divide(NetFile, MatrixAdjacency_Net, MaxNodeNum, NetName)\n",
    "\n",
    "similarity_StartTime = time.time()\n",
    "\n",
    "for Method in range(6):\n",
    "    if Method == 0:\n",
    "        print('----------SIM----------计算相似性矩阵1 7----------SIM----------')\n",
    "        print('----------Cn----------')\n",
    "        Matrix_similarity = similarity_indicators.CommonNeighbor.Cn(MatrixAdjacency_Train)\n",
    "        Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "    elif Method == 1:\n",
    "        print('----------RA----------')\n",
    "        Matrix_similarity = similarity_indicators.RA.RA(MatrixAdjacency_Train)\n",
    "        Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "    elif Method == 2:\n",
    "        print('----------Katz----------')\n",
    "        Matrix_similarity = similarity_indicators.Katz.Katz(MatrixAdjacency_Train)\n",
    "        Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "    elif Method == 3:\n",
    "        print('----------SIM----------基于随机游走----------SIM----------')\n",
    "        print('----------ACT----------')\n",
    "        Matrix_similarity = similarity_indicators.ACT.ACT(MatrixAdjacency_Train)\n",
    "        Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "    elif Method == 4:\n",
    "        print('----------AA----------')\n",
    "        Matrix_similarity = similarity_indicators.AA.AA(MatrixAdjacency_Train)\n",
    "        Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "    elif Method == 5:\n",
    "        print('----------SIM----------基于路径----------SIM----------')\n",
    "        print('----------LP----------')\n",
    "        Matrix_similarity = similarity_indicators.LP.LP(MatrixAdjacency_Train)\n",
    "        Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "    else:\n",
    "        print(\"Method Error!\")\n",
    "        \n",
    "similarity_EndTime = time.time()\n",
    "print('----------汇总----------')\n",
    "print(\"All SimilarityTime: {} s\".format(similarity_EndTime - similarity_StartTime))\n",
    "\n",
    "# Calculate AUC\n",
    "Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"\\nRunTime: {endTime - startTime} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Link Prediction start:\n",
      "\n",
      "DataShape......\n",
      "    数据集长度：4906\n",
      "    第一列节点长度：(750)\n",
      "    第二列节点长度：(1123)\n",
      "    节点数量为：1133\n",
      "    数据集长度：545\n",
      "    第一列节点长度：(314)\n",
      "    第二列节点长度：(373)\n",
      "    节点数量为：1105\n",
      "----------ACT----------\n",
      "    SimilarityTime: 1.3199919999897247 s\n",
      "----------Cn----------\n",
      "    SimilarityTime: 0.05268829999840818 s\n",
      "Precision@100: 0.000000\n",
      "Precision@200: 0.020000\n",
      "----------RA----------\n",
      "    SimilarityTime: 0.031250 s\n",
      "Precision@100: 0.000000\n",
      "Precision@200: 0.000000\n",
      "----------Katz----------\n",
      "    SimilarityTime: 0.078125 s\n",
      "Precision@100: 1.000000\n",
      "Precision@200: 1.000000\n",
      "----------ACT----------\n",
      "    SimilarityTime: 1.9909851000120398 s\n",
      "Precision@100: 0.400000\n",
      "Precision@200: 0.330000\n",
      "----------AA----------\n",
      "SimilarityTime: 0.218750 s\n",
      "Precision@100: 0.000000\n",
      "Precision@200: 0.000000\n",
      "----------LP----------\n",
      "    SimilarityTime: 0.937500 s\n",
      "Precision@100: 0.640000\n",
      "Precision@200: 0.670000\n",
      "    Calculation AUC......\n",
      "    AUC指标为：0.899011005353956\n",
      "    AUCTime：1.6114156246185303 s\n",
      "precision(L=100):0.11\n",
      "Precision(L=200):0.11\n",
      "----------汇总----------\n",
      "All SimilarityTime: 6.678839683532715 s\n",
      "\n",
      "RunTime: 6.714836597442627 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import Initialize\n",
    "import Evaluation_Indicators.AUC\n",
    "import similarity_indicators.CommonNeighbor\n",
    "import similarity_indicators.AA\n",
    "import similarity_indicators.RA\n",
    "import similarity_indicators.LP\n",
    "import similarity_indicators.Katz\n",
    "import similarity_indicators.ACT\n",
    "\n",
    "def precision(train_matrix, test_matrix, similarity_matrix, L, max_node_num):\n",
    "    \"\"\"计算链接预测的精确度。\n",
    "    参数:\n",
    "    train_matrix: 训练数据的邻接矩阵\n",
    "    test_matrix: 测试数据的邻接矩阵\n",
    "    similarity_matrix: 相似度得分矩阵\n",
    "    L: 计算精确度的参数\n",
    "    max_node_num: 网络中的总节点数量\n",
    "    返回:\n",
    "    precision_score: 链接预测的精确度\"\"\"\n",
    "    \n",
    "    # 基于训练数据调整相似度矩阵，并只保留上三角部分\n",
    "    adjusted_similarity_matrix = np.triu(similarity_matrix - similarity_matrix * train_matrix)\n",
    "\n",
    "    # 仅保留测试矩阵的上三角部分，以避免重复计算\n",
    "    test_matrix = np.triu(test_matrix)\n",
    "    # print(f\"test_matrix:{test_matrix}\")\n",
    "    # 计算测试集和不存在的边的并集\n",
    "    non_edge_mask = np.ones(max_node_num) - train_matrix - np.eye(max_node_num)\n",
    "    upper_triangular_non_edge_mask = np.triu(non_edge_mask)\n",
    "    \n",
    "    # 计算测试集和不存在的边的相似度得分\n",
    "    similarity_scores = adjusted_similarity_matrix * upper_triangular_non_edge_mask\n",
    "\n",
    "    # 将相似度得分按降序排序并获取索引\n",
    "    sort_index = np.argsort(similarity_scores, axis=None)[::-1]\n",
    "\n",
    "    # 获取前L条边的索引\n",
    "    top_L_indices = np.unravel_index(sort_index[:L], similarity_scores.shape)\n",
    "    # print(f\"top_L_indices:{top_L_indices}\")\n",
    "    # 计算在测试集中的前L条边的数量\n",
    "    m = np.sum(test_matrix[top_L_indices] != 0)\n",
    "    # print(f\"test_matrix[top_L_indices]:{test_matrix[top_L_indices]}\")\n",
    "    # print(f\"m:{m}\")\n",
    "    # 计算精确度\n",
    "    precision_score = float(m) / L\n",
    "\n",
    "    return precision_score\n",
    "\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "NetFile = 'Data/Email.txt'\n",
    "NetName = 'Email'\n",
    "\n",
    "print(\"\\nLink Prediction start:\\n\")\n",
    "TrainFile_Path = 'Data\\\\'+NetName+'\\\\Train.txt'\n",
    "if os.path.exists(TrainFile_Path):\n",
    "    Train_File = 'Data\\\\'+NetName+'\\\\Train.txt'\n",
    "    Test_File = 'Data\\\\'+NetName+'\\\\Test.txt'\n",
    "    MatrixAdjacency_Train, MatrixAdjacency_Test, MaxNodeNum = Initialize.Init2(Test_File, Train_File)\n",
    "else:\n",
    "    MatrixAdjacency_Net, MaxNodeNum = Initialize.Init(NetFile)\n",
    "    MatrixAdjacency_Train, MatrixAdjacency_Test = Initialize.Divide(NetFile, MatrixAdjacency_Net, MaxNodeNum, NetName)\n",
    "# print(f\"MatrixAdjacency_Test:\\n{MatrixAdjacency_Test}\")\n",
    "# print(f\"MatrixAdjacency_Test_sum:{np.sum(MatrixAdjacency_Test)}\")\n",
    "similarity_StartTime = time.time()\n",
    "print('----------ACT----------')\n",
    "Matrix_similarity = ACT(MatrixAdjacency_Train)\n",
    "for Method in range(6):\n",
    "    if Method == 0:\n",
    "        print('----------Cn----------')\n",
    "        Matrix_similarity = similarity_indicators.CommonNeighbor.Cn(MatrixAdjacency_Train)\n",
    "    elif Method == 1:\n",
    "        print('----------RA----------')\n",
    "        Matrix_similarity = similarity_indicators.RA.RA(MatrixAdjacency_Train)\n",
    "    elif Method == 2:\n",
    "        print('----------Katz----------')\n",
    "        Matrix_similarity = similarity_indicators.Katz.Katz(MatrixAdjacency_Train)\n",
    "    elif Method == 3:\n",
    "        print('----------ACT----------')\n",
    "        Matrix_similarity = similarity_indicators.ACT.ACT(MatrixAdjacency_Train)\n",
    "    elif Method == 4:\n",
    "        print('----------AA----------')\n",
    "        Matrix_similarity = similarity_indicators.AA.AA(MatrixAdjacency_Train)\n",
    "    elif Method == 5:\n",
    "        print('----------LP----------')\n",
    "        Matrix_similarity = similarity_indicators.LP.LP(MatrixAdjacency_Train)\n",
    "    else:\n",
    "        print(\"Method Error!\")\n",
    "\n",
    "Evaluation_Indicators.AUC.Calculation_AUC(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, MaxNodeNum)\n",
    "print(f\"precision(L=100):{precision(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, 100, MaxNodeNum)}\")\n",
    "print(f\"Precision(L=200):{precision(MatrixAdjacency_Train, MatrixAdjacency_Test, Matrix_similarity, 200, MaxNodeNum)}\")\n",
    "        \n",
    "similarity_EndTime = time.time()\n",
    "print('----------汇总----------')\n",
    "print(\"All SimilarityTime: {} s\".format(similarity_EndTime - similarity_StartTime))\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"\\nRunTime: {endTime - startTime} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网络大小：顶点数：1133，边数：5451,训练集比例：0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Divide(NetFile,netname,train_rate):\n",
    "    \"\"\"按比例划分训练集与测试集并且保证训练集连通\n",
    "    返回训练集、测试集邻接矩阵并写入文件中\"\"\"\n",
    "    #1.读入文件\n",
    "    data = np.loadtxt(NetFile)\n",
    "    enum = len(data)  # 网络总边数\n",
    "    enum_test = int(float(1 - train_rate) * enum)  # 测试集边数\n",
    "    V = set()  # 顶点集合\n",
    "    for item in data:\n",
    "        V.add(int(item[0]))\n",
    "        V.add(int(item[1]))\n",
    "    vnum = len(V)\n",
    "    # 2.创建邻接矩阵\n",
    "    A = np.zeros([vnum, vnum], dtype=int)\n",
    "    for item in data:\n",
    "        v1 = int(item[0]) - 1\n",
    "        v2 = int(item[1]) - 1\n",
    "        A[v1, v2] = A[v2, v1] = 1\n",
    "    #3.计算训练集以及测试集邻接矩阵\n",
    "    Matrix_Train = A    #初始训练集\n",
    "    # print(f'初始训练集\\n{Matrix_Train}')\n",
    "    Matrix_Test = np.zeros((vnum, vnum))#初始测试集\n",
    "    # 3.1在原有边中随机选enum_test条边，存在测试集合中，并从原集合中删除\n",
    "    while len(np.nonzero(Matrix_Test)[0]) < enum_test:\n",
    "        index = np.random.randint(low=0, high=len(data), size=1)\n",
    "        v1 = int(data[index, 0]) - 1\n",
    "        v2 = int(data[index, 1]) - 1\n",
    "        Matrix_Train[v1, v2] = Matrix_Train[v2, v1] = 0\n",
    "        # 3.2判断所选边的两个端点是否可达，若不可达需要重新选边\n",
    "        temp = Matrix_Train[v1]  # 存储v1的邻居\n",
    "        flag = 0  # 标记这条边是否可以被删除\n",
    "        count = 0  # 记录v1到v2之间的步数\n",
    "        v1_v2 = np.dot(temp, Matrix_Train) + temp  # v1 2步可到达的点\n",
    "        if v1_v2[v2] > 0:\n",
    "            flag = 1\n",
    "        else:\n",
    "            count = 1\n",
    "        temp1 = np.int64(v1_v2 > 0)\n",
    "        # 3.3直到v1可达的点到达稳定状态，如果仍然不能到达v2，则v1-v2不可达\n",
    "        while len((temp1 - temp).nonzero()[0]) != 0:\n",
    "            temp = temp1\n",
    "            v1_v2 = np.dot(temp, Matrix_Train) + temp# v1 n步可到达的点\n",
    "            count += 1\n",
    "            if v1_v2[v2] > 0:\n",
    "                flag = 1\n",
    "                break\n",
    "            if count >= vnum:\n",
    "                flag = 0\n",
    "        if flag == 1:\n",
    "            data = np.delete(data, index, axis=0)\n",
    "            Matrix_Test[v1, v2] = 1\n",
    "        else:\n",
    "            data = np.delete(data, index, axis=0)\n",
    "            Matrix_Train[v1, v2] = Matrix_Train[v2, v1] = 1\n",
    "    Matrix_Test = Matrix_Test + Matrix_Test.T\n",
    "    print(f'网络大小：顶点数：{vnum}，边数：{enum},训练集比例：{train_rate}')\n",
    "    # print(f'训练集邻接矩阵：\\n{Matrix_Train}\\n测试集邻接矩阵\\n{Matrix_Test}')\n",
    "    #4.写入文件\n",
    "    WriteFile(\"Train\", Matrix_Train, netname)\n",
    "    WriteFile(\"Test\", Matrix_Test, netname)\n",
    "    return Matrix_Train, Matrix_Test\n",
    " \n",
    "def WriteFile(filename,Matrix,netname):\n",
    "    M=np.triu(Matrix)\n",
    "    index=np.argwhere(M!=0)\n",
    "    with open (f'data/{netname}/{filename}.txt','w') as f:\n",
    "        np.savetxt(f,index,fmt=\"%d\")\n",
    "Divide('Email.txt','Email',0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------Cn----------\n",
    "    SimilarityTime: 0.023472100001526996 s\n",
    "    Calculation AUC......\n",
    "    AUC指标为：0.844622992266508\n",
    "    AUCTime：1.0817391872406006 s\n",
    "AUC:  0.844622992266508\n",
    "Precision@100:  0.26\n",
    "Precision@200:  0.245\n",
    "----------RA----------\n",
    "    SimilarityTime: 0.265625 s\n",
    "    Calculation AUC......\n",
    "    AUC指标为：0.8469385782272457\n",
    "    AUCTime：1.7076497077941895 s\n",
    "AUC:  0.8469385782272457\n",
    "Precision@100:  0.27\n",
    "Precision@200:  0.2\n",
    "----------Katz----------\n",
    "    SimilarityTime: 0.828125 s\n",
    "    Calculation AUC......\n",
    "    AUC指标为：0.8945226055919095\n",
    "    AUCTime：1.2692959308624268 s\n",
    "AUC:  0.8945226055919095\n",
    "Precision@100:  0.3\n",
    "Precision@200:  0.23\n",
    "----------ACT----------\n",
    "    SimilarityTime: 1.202463199995691 s\n",
    "    Calculation AUC......\n",
    "    AUC指标为：0.7892088042831648\n",
    "    AUCTime：1.1468257904052734 s\n",
    "AUC:  0.7892088042831648\n",
    "Precision@100:  0.0\n",
    "Precision@200:  0.0\n",
    "----------AA----------\n",
    "SimilarityTime: 0.046875 s\n",
    "    Calculation AUC......\n",
    "    AUC指标为：0.8475981558596074\n",
    "    AUCTime：1.156388282775879 s\n",
    "AUC:  0.8475981558596074\n",
    "Precision@100:  0.33\n",
    "Precision@200:  0.25\n",
    "----------LP----------\n",
    "    SimilarityTime: 0.328125 s\n",
    "    Calculation AUC......\n",
    "    AUC指标为：0.8405837299226651\n",
    "    AUCTime：1.108668327331543 s\n",
    "AUC:  0.8405837299226651\n",
    "Precision@100:  0.06\n",
    "Precision@200:  0.065"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真正的第五次作业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Method    AUC  Precision(L=100)  Precision(L=200)\n",
      "0     Cn  0.885              0.32             0.280\n",
      "1     RA  0.887              0.33             0.220\n",
      "2   Katz  0.953              0.31             0.275\n",
      "3    ACT  0.835              0.06             0.055\n",
      "4     AA  0.888              0.39             0.275\n",
      "5     LP  0.898              0.11             0.110\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Method': ['Cn', 'RA', 'Katz', 'ACT', 'AA', 'LP'],\n",
    "    'AUC': [0.885, 0.887, 0.953, 0.835, 0.888, 0.898],\n",
    "    'Precision(L=100)': [0.32, 0.33, 0.31, 0.06, 0.39, 0.11],\n",
    "    'Precision(L=200)': [0.28, 0.22, 0.275, 0.055, 0.275, 0.11],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [0, 5, 6],\n",
       "       [0, 0, 9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.triu([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
