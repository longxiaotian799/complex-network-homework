{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 247\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39m# 从文件中读取边列表，创建一个图，其中节点的类型为整数，边的权重为整数\u001b[39;00m\n\u001b[0;32m    242\u001b[0m G \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mread_edgelist(\n\u001b[0;32m    243\u001b[0m     file_path,\n\u001b[0;32m    244\u001b[0m     nodetype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m,\n\u001b[0;32m    245\u001b[0m     data\u001b[39m=\u001b[39m((\u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mint\u001b[39m),)\n\u001b[0;32m    246\u001b[0m )\n\u001b[1;32m--> 247\u001b[0m \u001b[39mprint\u001b[39m(eigenvector_centrality(G))\n",
      "Cell \u001b[1;32mIn[20], line 77\u001b[0m, in \u001b[0;36meigenvector_centrality\u001b[1;34m(adj_matrix, max_iter, tol)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meigenvector_centrality\u001b[39m(adj_matrix, max_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, tol\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m):\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mallclose(adj_matrix, adj_matrix\u001b[39m.\u001b[39;49mT):\n\u001b[0;32m     78\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAdjacency matrix is not symmetric.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m     n \u001b[39m=\u001b[39m adj_matrix\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "def breadth_first_search(G, source, target=None):\n",
    "    '''\n",
    "    输入：\n",
    "\n",
    "    G：一个图，表示节点及其相互之间的连接关系。在这里，它应该是一个 NetworkX 图对象。\n",
    "    source：源节点，是 BFS 算法的起点。\n",
    "    target（可选）：目标节点，如果提供了这个参数，函数将返回源节点到目标节点的最短距离。\n",
    "    输出：\n",
    "\n",
    "    如果没有指定目标节点，函数将返回一个字典，键为图中的每个节点，值为一个元组，包含两个元素：该节点到源节点的最短距离和该节点是否已被访问过。\n",
    "    如果指定了目标节点，函数将返回一个整数，表示源节点到目标节点的最短距离。\n",
    "    '''\n",
    "    # 初始化队列，将源节点加入队列\n",
    "    queue = deque([source])\n",
    "    # 为图中的每个节点创建一个字典，键为节点，值为一个包含两个元素的元组：距离和是否访问过的布尔值\n",
    "    node_info = {node: (0, False) for node in G.nodes}\n",
    "    # 将源节点的距离设置为 0，并将其访问状态设置为 True\n",
    "    node_info[source] = (0, True)\n",
    "\n",
    "    # 当队列非空时，继续执行循环\n",
    "    while queue:\n",
    "        # 从队列左侧移除并返回一个节点，将其作为当前节点\n",
    "        current_node = queue.popleft()\n",
    "\n",
    "        # 如果目标节点不为空，且当前节点等于目标节点，退出循环\n",
    "        if target is not None and current_node == target:\n",
    "            break\n",
    "\n",
    "        # 获取当前节点的相邻节点列表\n",
    "        neighbors = list(G.neighbors(current_node))\n",
    "        # 遍历相邻节点\n",
    "        for neighbor in neighbors:\n",
    "            # 获取相邻节点的距离和访问状态\n",
    "            distance, visited = node_info[neighbor]\n",
    "            # 如果相邻节点未访问过\n",
    "            if not visited:\n",
    "                # 更新相邻节点的距离和访问状态\n",
    "                node_info[neighbor] = (node_info[current_node][0] + 1, True)\n",
    "                # 将相邻节点添加到队列的右侧\n",
    "                queue.append(neighbor)\n",
    "\n",
    "    # 如果没有指定目标节点，返回包含所有节点信息的字典\n",
    "    if target is None:\n",
    "        return node_info\n",
    "    # 如果指定了目标节点，返回目标节点的距离\n",
    "    else:\n",
    "        return node_info[target][0]\n",
    "\n",
    "def bfs(graph, start_node, visited):\n",
    "    queue = [start_node]\n",
    "    visited.add(start_node)\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.pop(0)\n",
    "        for neighbor in graph[current_node]:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "def get_largest_connected_component(graph):\n",
    "    visited = set()\n",
    "    largest_cc = set()\n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            current_cc = set()\n",
    "            bfs(graph, node, current_cc)\n",
    "            if len(current_cc) > len(largest_cc):\n",
    "                largest_cc = current_cc\n",
    "    return largest_cc\n",
    "# 幂迭代法计算特征向量中心性\n",
    "def eigenvector_centrality(adj_matrix, max_iter=100, tol=1e-6):\n",
    "    if not np.allclose(adj_matrix, adj_matrix.T):\n",
    "        print(\"Adjacency matrix is not symmetric.\")\n",
    "    n = adj_matrix.shape[0]\n",
    "    x = np.random.rand(n, 1)\n",
    "    x /= np.linalg.norm(x)\n",
    "    for _ in range(max_iter):\n",
    "        x_next = adj_matrix @ x\n",
    "        x_next /= np.linalg.norm(x_next)\n",
    "        if np.linalg.norm(x_next - x) < tol:\n",
    "            break\n",
    "        x = x_next\n",
    "    return x\n",
    "    \n",
    "def Closeness_Centrality(G):\n",
    "    # 初始化一个零矩阵，用于存储图中所有节点间的最短路径长度\n",
    "    shoretest_path_matrix = np.zeros((len(G.nodes()), len(G.nodes())))\n",
    "    \n",
    "    # 创建一个字典，将图中的节点映射到它们在矩阵中的索引\n",
    "    dic = dict(zip(G.nodes(), range(len(G.nodes()))))\n",
    "    \n",
    "    # 遍历图中的所有节点，计算它们之间的最短路径长度\n",
    "    for start in G.nodes:\n",
    "        for end in G.nodes:\n",
    "            if start != end:\n",
    "                # 如果当前节点对的最短路径尚未计算\n",
    "                if shoretest_path_matrix[dic.get(start), dic.get(end)] == 0:\n",
    "                    # 使用广度优先搜索算法计算最短路径长度，并将其存储在矩阵中\n",
    "                    shoretest_path_matrix[dic.get(start), dic.get(end)] = breadth_first_search(G, start, end)\n",
    "                    continue\n",
    "    \n",
    "    # 打印最短路径矩阵\n",
    "    print(shoretest_path_matrix)\n",
    "    \n",
    "    # 计算并返回接近中心性\n",
    "    return (len(G.nodes()) - 1) / shoretest_path_matrix.sum(axis = 1)\n",
    "\n",
    "    \n",
    "\n",
    "def degree_centralized_distribution(G):\n",
    "    degree = [d[1] for d in G.degree()]  # 获取图中每个节点的度（连接的边数）\n",
    "    \n",
    "    # 绘制每个节点的度中心化分布的柱状图\n",
    "    plt.bar(G.nodes(), np.divide(degree, (len(G.nodes()) - 1)))\n",
    "    plt.xlabel('Degree')  # 设置x轴标签为“Degree”\n",
    "    plt.ylabel('Count')  # 设置y轴标签为“Count”\n",
    "    plt.title('Degree Centralised Distribution')  # 设置图表标题为“Degree Centralised Distribution”\n",
    "    plt.show()  # 显示图表\n",
    "    \n",
    "    # 返回每个节点的度中心化分布值\n",
    "    return np.divide(degree, (len(G.nodes()) - 1))\n",
    "\n",
    "def bfs_shortest_paths(G, source):\n",
    "    visited = {source: 0}  # 初始化已访问节点字典，将起始节点的访问深度设为0\n",
    "    queue = [source]  # 初始化队列，将起始节点加入队列\n",
    "    paths = {node: [] for node in G.nodes}  # 初始化路径字典，用于存储从起始节点到每个节点的最短路径\n",
    "    paths[source] = [[source]]  # 将起始节点的路径设为包含自身的列表\n",
    "\n",
    "    # 当队列非空时，继续执行循环\n",
    "    while queue:\n",
    "        current = queue.pop(0)  # 从队列中取出第一个节点，并将其从队列中移除\n",
    "        neighbors = G[current]  # 获取当前节点的邻居节点\n",
    "\n",
    "        # 遍历邻居节点\n",
    "        for neighbor in neighbors:\n",
    "            # 如果邻居节点没有被访问过\n",
    "            if neighbor not in visited:\n",
    "                visited[neighbor] = visited[current] + 1  # 将邻居节点的访问深度设为当前节点访问深度加1\n",
    "                queue.append(neighbor)  # 将邻居节点加入队列\n",
    "\n",
    "            # 如果邻居节点的访问深度等于当前节点访问深度加1\n",
    "            if visited[neighbor] == visited[current] + 1:\n",
    "                # 更新从起始节点到邻居节点的最短路径\n",
    "                paths[neighbor] += [path + [neighbor] for path in paths[current]]\n",
    "\n",
    "    return paths  # 返回从起始节点到每个节点的最短路径字典\n",
    "\n",
    "\n",
    "def betweenness_centrality(G):\n",
    "    shoretest_path_matrix = shortest_path_number(G)  # 计算网络图中所有节点对之间的最短路径数量\n",
    "    # np.savetxt(\"homework3.3.txt\", shoretest_path_matrix, fmt='%d')  # 将最短路径数量矩阵以整数形式写入文件\n",
    "    dic = dict(zip(G.nodes(), range(len(G.nodes()))))  # 创建一个将节点映射到其索引的字典\n",
    "    # 初始化一个用于存储分子（通过特定节点的最短路径数量）的三维数组\n",
    "    Numerator = [np.zeros((len(G.nodes()), len(G.nodes()))) for _ in range(len(G.nodes()))]\n",
    "\n",
    "    # 遍历网络图中的每个节点\n",
    "    for node in G.nodes:\n",
    "        # 遍历除当前节点以外的所有起始节点\n",
    "        for start in [n for n in G.nodes if n != node]:\n",
    "            # 遍历除当前节点以外的所有结束节点\n",
    "            for end in [n for n in G.nodes if n != node]:\n",
    "                if start != end:\n",
    "                    # 计算从起始节点到结束节点的最短路径中通过当前节点的路径数量\n",
    "                    shortest_paths = bfs_shortest_paths(G, start)\n",
    "                    count = sum(node in path for path in shortest_paths[end])\n",
    "                    Numerator[dic.get(node)][dic.get(start)][dic.get(end)] += count\n",
    "\n",
    "    # 将 shoretest_path_matrix 转换为 NumPy 数组\n",
    "    shoretest_path_matrix_np = np.array(shoretest_path_matrix)\n",
    "    Numerator_np = np.array(Numerator)\n",
    "    \n",
    "    re = []  # 初始化用于存储结果的列表\n",
    "    mask = shoretest_path_matrix_np != 0  # 创建一个掩码，标识 shoretest_path_matrix_np 中非零元素的位置\n",
    "\n",
    "    for i in Numerator_np:\n",
    "        # 初始化一个与 i 相同形状的全零矩阵\n",
    "        result = np.zeros_like(i)\n",
    "\n",
    "        # 只对 shoretest_path_matrix_np 中非零元素对应的位置进行除法操作\n",
    "        result[mask] = i[mask] / shoretest_path_matrix_np[mask]\n",
    "\n",
    "        re.append(np.sum(result))\n",
    "    re = np.array(re)\n",
    "    \n",
    "    # 输出网络图的介数中心性（使用 NetworkX 计算）\n",
    "    print(\"betweenness_centrality NetworkX:\", nx.betweenness_centrality(G,normalized=True))\n",
    "\n",
    "    # 输出结果\n",
    "    result = dict(zip(G.nodes(), re/((len(G.nodes()) - 1) * (len(G.nodes()) - 2))))\n",
    "    return result\n",
    "    \n",
    "def shortest_path_number(G):\n",
    "    n = G.number_of_nodes()  # 获取图 G 的节点数\n",
    "    matrix = [np.zeros((n, n))]  # 初始化一个 n*n 的零矩阵\n",
    "    shortest_path_number = np.zeros((n, n))  # 初始化一个 n*n 的零矩阵\n",
    "    np.fill_diagonal(shortest_path_number, np.inf)  # 将 shortest_path_number 的对角线上的值设置为正无穷\n",
    "    adj_matrix = np.array(nx.to_numpy_array(G))  # 将图 G 转换成邻接矩阵\n",
    "    matrix = adj_matrix  # 将邻接矩阵赋值给 matrix\n",
    "    np.fill_diagonal(shortest_path_number, np.inf)  # 将 shortest_path_number 的对角线上的值设置为正无穷\n",
    "    for i in range(1, n):  # 进行 n-1 次迭代\n",
    "        for p in range(n):  # 遍历所有节点对\n",
    "            for q in range(n):\n",
    "                if q != p:  # 排除节点到自身的情况\n",
    "                    if matrix[p][q] != 0 and shortest_path_number[p][q] == 0:  # 如果节点 p 和节点 q 之间有边，并且它们之间的最短路径还没有被计算出来\n",
    "                        shortest_path_number[p][q] = matrix[p][q]  # 将它们之间的距离作为它们之间的最短路径\n",
    "        matrix = matrix @ adj_matrix  # 计算 matrix 的下一次幂\n",
    "    # 将对角线上的值设置为0，因为节点到自身的距离为0\n",
    "    np.fill_diagonal(shortest_path_number, 0)\n",
    "    return shortest_path_number\n",
    "    \n",
    "def k_shell_decomposition(graph):\n",
    "    k_shell = {}  # 创建一个空字典，用于存储每个节点的k-壳值\n",
    "    k = 1  # 初始化k的值为1，用于表示当前计算的k-壳层级\n",
    "\n",
    "    # 当图中仍然有节点时，继续执行循环\n",
    "    while graph.nodes():\n",
    "        nodes_to_remove = []  # 创建一个空列表，用于存储本轮迭代中需要移除的节点\n",
    "\n",
    "        # 遍历图中的所有节点\n",
    "        for node in graph.nodes():\n",
    "            # 如果当前节点的度（连接的边数）小于等于k\n",
    "            if graph.degree(node) <= k:\n",
    "                nodes_to_remove.append(node)  # 将当前节点添加到需要移除的节点列表中\n",
    "                k_shell[node] = k  # 将当前节点的k-壳值设置为k\n",
    "\n",
    "        # 如果本轮迭代没有需要移除的节点\n",
    "        if not nodes_to_remove:\n",
    "            k += 1  # 将k的值加1，计算下一个k-壳层级\n",
    "        else:\n",
    "            graph.remove_nodes_from(nodes_to_remove)  # 从图中移除本轮迭代中所有需要移除的节点\n",
    "\n",
    "    return k_shell  # 返回字典k_shell，其中包含每个节点的k-壳值\n",
    "\n",
    "\n",
    "file_path = \"karate.txt\"\n",
    "# 从文件中读取边列表，创建一个图，其中节点的类型为整数，边的权重为整数\n",
    "G = nx.read_edgelist(\n",
    "    file_path,\n",
    "    nodetype=int,\n",
    "    data=(('weight', int),)\n",
    ")\n",
    "print(eigenvector_centrality(G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35549162]\n",
      " [0.26596009]\n",
      " [0.3171926 ]\n",
      " [0.21117995]\n",
      " [0.07596896]\n",
      " [0.0794832 ]\n",
      " [0.0794832 ]\n",
      " [0.17095998]\n",
      " [0.22740397]\n",
      " [0.07596896]\n",
      " [0.0528558 ]\n",
      " [0.08425477]\n",
      " [0.22647294]\n",
      " [0.0923997 ]\n",
      " [0.14791266]\n",
      " [0.0923997 ]\n",
      " [0.19103388]\n",
      " [0.1747583 ]\n",
      " [0.10267427]\n",
      " [0.13347712]\n",
      " [0.13107779]\n",
      " [0.3086438 ]\n",
      " [0.02363567]\n",
      " [0.3733629 ]\n",
      " [0.10140323]\n",
      " [0.10140323]\n",
      " [0.10140323]\n",
      " [0.10140323]\n",
      " [0.10140323]\n",
      " [0.15011845]\n",
      " [0.05920637]\n",
      " [0.1349607 ]\n",
      " [0.05705236]\n",
      " [0.07557936]]\n",
      "{1: 0.35548349418519426, 2: 0.26595387045450236, 3: 0.3171893899684447, 4: 0.21117407832057056, 5: 0.0759664588165738, 6: 0.07948057788594245, 7: 0.07948057788594245, 8: 0.1709551149803543, 9: 0.22740509147166046, 11: 0.0759664588165738, 12: 0.05285416945233646, 13: 0.08425192086558085, 14: 0.22646969838808148, 18: 0.0923967566684595, 20: 0.14791134007618667, 22: 0.0923967566684595, 32: 0.19103626979791702, 31: 0.17476027834493088, 10: 0.10267519030637758, 28: 0.13347932684333308, 29: 0.13107925627221215, 33: 0.3086510477336959, 17: 0.02363479426059687, 34: 0.37337121301323495, 15: 0.10140627846270833, 16: 0.10140627846270833, 19: 0.10140627846270833, 21: 0.10140627846270833, 23: 0.10140627846270833, 24: 0.15012328691726787, 26: 0.05920820250279008, 30: 0.13496528673866567, 25: 0.057053735638028055, 27: 0.07558192219009326}\n"
     ]
    }
   ],
   "source": [
    "def degree_centrality(G):\n",
    "    degree = [d[1] for d in G.degree()]  # 获取图中每个节点的度（连接的边数）\n",
    "    \n",
    "    # 绘制每个节点的度中心化分布的柱状图\n",
    "    plt.bar(G.nodes(), np.divide(degree, (len(G.nodes()) - 1)))\n",
    "    plt.xlabel('Degree')  # 设置x轴标签为“Degree”\n",
    "    plt.ylabel('Count')  # 设置y轴标签为“Count”\n",
    "    plt.title('Degree Centrality')  # 设置图表标题为“Degree Centrality”\n",
    "    plt.show()  # 显示图表\n",
    "    \n",
    "    # 返回每个节点的度中心化分布值\n",
    "    return np.divide(degree, (len(G.nodes()) - 1))\n",
    "\n",
    "file_path = \"karate.txt\"\n",
    "# 从文件中读取边列表，创建一个图，其中节点的类型为整数，边的权重为整数\n",
    "G = nx.read_edgelist(\n",
    "    file_path,\n",
    "    nodetype=int,\n",
    "    data=(('weight', int),)\n",
    ")\n",
    "print(eigenvector_centrality(nx.to_numpy_array(G)))\n",
    "print(nx.eigenvector_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(betweenness_centrality(G))\n",
    "# nx.draw(G, with_labels=True)\n",
    "# plt.show()\n",
    "# 将图转换为 NumPy 矩阵\n",
    "# adj_matrix = nx.to_numpy_matrix(G)\n",
    "# print(f\"own code degeree contrality: {degree_centralized_distribution(G)}\")\n",
    "# print(f\"NetworkX: {nx.degree_centrality(G)}\")\n",
    "# print(f\"own code closeness contrality: {Closeness_Centrality(G)}\")\n",
    "# print(f\"NetworkX: {nx.closeness_centrality(G)}\")\n",
    "# path = [] \n",
    "\n",
    "# 计算特征向量中心性\n",
    "# centrality = nx.eigenvector_centrality(G)\n",
    "\n",
    "# 判断是否是连通图\n",
    "# if not is_connected(G):\n",
    "#     G_set = get_largest_connected_component(G)\n",
    "#     G_list = list(G_set)\n",
    "#     # print(f\"Largest connected component is {G_list}\")\n",
    "#     for i in list(G.nodes()):\n",
    "#         if i not in G_list:\n",
    "#             G.remove_node(i)\n",
    "# print(f\"networkX result based on norm 1:{nx.eigenvector_centrality(G)}\")\n",
    "# print(f\"eigenvector_centrality based on norm 2:{eigenvector_centrality(adj_matrix)}\")\n",
    "betweenness_centrality(G)\n",
    "# save_path = \"shoretest_path_matrix_sum.txt\"\n",
    "# np.savetxt(save_path, shoretest_path_matrix.sum(axis = 1) / (len(G.nodes()) - 1), fmt = '%f', delimiter = ' ')\n",
    "# # 输出结果\n",
    "# print(centrality)\n",
    "# nodes = [n for n in G.nodes() if n != 27]\n",
    "# for n in nodes:\n",
    "#     path.append(breadth_first_search(G, 27, n))\n",
    "# print(path)\n",
    "#     path.append(breadth_first_search(G, node))\n",
    "# dict = zip(G.nodes(), path)\n",
    "# print(list(dict))\n",
    "    \n",
    "# Centrifugal_centrality = []\n",
    "# for node in G.nodes():\n",
    "#     nodes = [n for n in G.nodes() if n != node]\n",
    "#     for n in nodes:\n",
    "#         path.append(breadth_first_search(G, node, n))\n",
    "#     Centrifugal_centrality.append(max(path))\n",
    "#     path = []\n",
    "# List = zip(G.nodes(), Centrifugal_centrality)\n",
    "# print(list(List))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
