{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "import networkx as nx\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "\n",
    "# Set up the model\n",
    "model = ep.IndependentCascadesModel(G)\n",
    "\n",
    "# Set the model parameters\n",
    "config = mc.Configuration()\n",
    "config.add_model_parameter('fraction_infected', 0.1)\n",
    "config.add_model_parameter('infected', [])\n",
    "\n",
    "# Set the node parameters\n",
    "for node in G.nodes():\n",
    "    config.add_node_configuration(\"threshold\", node, 0.1)\n",
    "    config.add_node_configuration(\"infected\", node, False)\n",
    "\n",
    "# Set the initial infected nodes using degree centrality\n",
    "deg_cen = nx.degree_centrality(G)\n",
    "sorted_nodes = sorted(deg_cen.items(), key=lambda x: x[1], reverse=True)\n",
    "k = 5\n",
    "top_k = [node[0] for node in sorted_nodes[:k]]\n",
    "config.add_model_initial_configuration(\"Infected\", top_k)\n",
    "\n",
    "model.set_initial_status(config)\n",
    "\n",
    "# Run the simulation\n",
    "iterations = model.iteration_bunch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "import networkx as nx\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "\n",
    "# Set up the model\n",
    "model = ep.LinearThresholdModel(G)\n",
    "\n",
    "# Set the model parameters\n",
    "config = mc.Configuration()\n",
    "config.add_model_parameter('fraction_infected', 0.1)\n",
    "config.add_model_parameter('infected', [])\n",
    "\n",
    "# Set the node parameters\n",
    "for node in G.nodes():\n",
    "    config.add_node_configuration(\"threshold\", node, 0.1)\n",
    "    config.add_node_configuration(\"infected\", node, False)\n",
    "\n",
    "# Set the initial infected nodes using degree discount\n",
    "degree_dict = dict(G.degree())\n",
    "degree_discount = {}\n",
    "for node in G.nodes():\n",
    "    neighbors = [n for n in G.neighbors(node)]\n",
    "    neighbor_degree = sum([degree_dict[n] for n in neighbors])\n",
    "    degree_discount[node] = neighbor_degree / degree_dict[node]\n",
    "sorted_nodes = sorted(degree_discount.items(), key=lambda x: x[1], reverse=True)\n",
    "k = 5\n",
    "top_k = [node[0] for node in sorted_nodes[:k]]\n",
    "config.add_model_initial_configuration(\"Infected\", top_k)\n",
    "\n",
    "model.set_initial_status(config)\n",
    "\n",
    "# Run the simulation\n",
    "iterations = model.iteration_bunch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# 定义文件路径\n",
    "file_path = 'email.txt'\n",
    "\n",
    "# 从文件中读取边列表，创建一个图，其中节点的类型为整数，边的权重为整数\n",
    "G = nx.read_edgelist(\n",
    "    file_path,\n",
    "    nodetype=int,\n",
    "    data=(('weight', int),)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "传播轮次: 27\n",
      "激活节点数: 1117\n"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "# 定义度中心性方法\n",
    "def degree_centrality(G, k):\n",
    "    # 计算每个节点的度中心性\n",
    "    deg_cen = {v: d for v, d in G.degree()}\n",
    "    # 根据度中心性从高到低排序\n",
    "    top_k = nlargest(k, deg_cen, key=deg_cen.get)\n",
    "    return top_k\n",
    "\n",
    "# 定义IC模型传播函数\n",
    "def icm(G, seeds, p):\n",
    "    # 初始化传播节点集合\n",
    "    activated = set(seeds)\n",
    "    # 初始化传播轮次\n",
    "    rounds = 0\n",
    "    # 迭代直到没有新节点被激活\n",
    "    while True:\n",
    "        # 初始化本轮次被激活的节点集合\n",
    "        newly_activated = set()\n",
    "        # 遍历所有已经激活的节点\n",
    "        for node in activated:\n",
    "            # 遍历该节点的所有邻居\n",
    "            for neighbor in G.neighbors(node):\n",
    "                # 如果该邻居节点没有被激活\n",
    "                if neighbor not in activated:\n",
    "                    # 以概率p尝试激活该邻居节点\n",
    "                    if random() < p:\n",
    "                        newly_activated.add(neighbor)\n",
    "        # 如果没有新节点被激活，则停止传播\n",
    "        if not newly_activated:\n",
    "            break\n",
    "        # 将本轮次激活的节点添加到总体集合中\n",
    "        activated |= newly_activated\n",
    "        # 增加传播轮次计数器\n",
    "        rounds += 1\n",
    "    # 返回传播轮次和激活节点集合\n",
    "    return rounds, activated\n",
    "\n",
    "# 设定随机种子以便结果可重现\n",
    "seed(1234)\n",
    "\n",
    "# 选择度中心性种子节点\n",
    "k = 10\n",
    "seeds = degree_centrality(G, k)\n",
    "\n",
    "# 运行IC模型并输出结果\n",
    "p = 0.1\n",
    "rounds, activated = icm(G, seeds, p)\n",
    "print(f\"传播轮次: {rounds}\")\n",
    "print(f\"激活节点数: {len(activated)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "def breadth_first_search(G, source, target=None):\n",
    "    '''\n",
    "    输入：\n",
    "\n",
    "    G：一个图，表示节点及其相互之间的连接关系。在这里，它应该是一个 NetworkX 图对象。\n",
    "    source：源节点，是 BFS 算法的起点。\n",
    "    target（可选）：目标节点，如果提供了这个参数，函数将返回源节点到目标节点的最短距离。\n",
    "    输出：\n",
    "\n",
    "    如果没有指定目标节点，函数将返回一个字典，键为图中的每个节点，值为一个元组，包含两个元素：该节点到源节点的最短距离和该节点是否已被访问过。\n",
    "    如果指定了目标节点，函数将返回一个整数，表示源节点到目标节点的最短距离。\n",
    "    '''\n",
    "    # 初始化队列，将源节点加入队列\n",
    "    queue = deque([source])\n",
    "    # 为图中的每个节点创建一个字典，键为节点，值为一个包含两个元素的元组：距离和是否访问过的布尔值\n",
    "    node_info = {node: (0, False) for node in G.nodes}\n",
    "    # 将源节点的距离设置为 0，并将其访问状态设置为 True\n",
    "    node_info[source] = (0, True)\n",
    "\n",
    "    # 当队列非空时，继续执行循环\n",
    "    while queue:\n",
    "        # 从队列左侧移除并返回一个节点，将其作为当前节点\n",
    "        current_node = queue.popleft()\n",
    "\n",
    "        # 如果目标节点不为空，且当前节点等于目标节点，退出循环\n",
    "        if target is not None and current_node == target:\n",
    "            break\n",
    "\n",
    "        # 获取当前节点的相邻节点列表\n",
    "        neighbors = list(G.neighbors(current_node))\n",
    "        # 遍历相邻节点\n",
    "        for neighbor in neighbors:\n",
    "            # 获取相邻节点的距离和访问状态\n",
    "            distance, visited = node_info[neighbor]\n",
    "            # 如果相邻节点未访问过\n",
    "            if not visited:\n",
    "                # 更新相邻节点的距离和访问状态\n",
    "                node_info[neighbor] = (node_info[current_node][0] + 1, True)\n",
    "                # 将相邻节点添加到队列的右侧\n",
    "                queue.append(neighbor)\n",
    "\n",
    "    # 如果没有指定目标节点，返回包含所有节点信息的字典\n",
    "    if target is None:\n",
    "        return node_info\n",
    "    # 如果指定了目标节点，返回目标节点的距离\n",
    "    else:\n",
    "        return node_info[target][0]\n",
    "\n",
    "def bfs(graph, start_node, visited):\n",
    "    queue = [start_node]\n",
    "    visited.add(start_node)\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.pop(0)\n",
    "        for neighbor in graph[current_node]:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "def is_connected(G):\n",
    "    start = next(iter(G.nodes))  # 选择任意一个节点作为起点\n",
    "    target = None  # 设置目标节点为 None，因为我们只关心访问的节点数量\n",
    "    node_distances = breadth_first_search(G, start, target)\n",
    "    \n",
    "    visited_nodes = [node for node, (distance, visited) in node_distances.items() if visited]\n",
    "    \n",
    "    if len(visited_nodes) == len(G.nodes):\n",
    "        print(\"Graph is connected\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Graph is not connected\")\n",
    "        return False\n",
    "\n",
    "def get_largest_connected_component(graph):\n",
    "    visited = set()\n",
    "    largest_cc = set()\n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            current_cc = set()\n",
    "            bfs(graph, node, current_cc)\n",
    "            if len(current_cc) > len(largest_cc):\n",
    "                largest_cc = current_cc\n",
    "    return largest_cc\n",
    "# 幂迭代法计算特征向量中心性\n",
    "def eigenvector_centrality(adj_matrix, max_iter=100, tol=1e-6):\n",
    "    if not np.allclose(adj_matrix, adj_matrix.T):\n",
    "        print(\"Adjacency matrix is not symmetric.\")\n",
    "    n = adj_matrix.shape[0]\n",
    "    x = np.random.rand(n, 1)\n",
    "    x /= np.linalg.norm(x)\n",
    "    for _ in range(max_iter):\n",
    "        x_next = adj_matrix @ x\n",
    "        x_next /= np.linalg.norm(x_next)\n",
    "        if np.linalg.norm(x_next - x) < tol:\n",
    "            break\n",
    "        x = x_next\n",
    "    return x\n",
    "    \n",
    "def Closeness_Centrality(G):\n",
    "    shoretest_path_matrix = np.zeros((len(G.nodes()), len(G.nodes())))\n",
    "    dic = dict(zip(G.nodes(), range(len(G.nodes()))))\n",
    "    for start in G.nodes:\n",
    "        for end in G.nodes:\n",
    "            if start != end:\n",
    "                if shoretest_path_matrix[dic.get(start), dic.get(end)] == 0:\n",
    "                    shoretest_path_matrix[dic.get(start), dic.get(end)] = breadth_first_search(G, start, end) \n",
    "                    continue\n",
    "    print(shoretest_path_matrix)\n",
    "    return (len(G.nodes()) - 1) / shoretest_path_matrix.sum(axis = 1)\n",
    "    \n",
    "\n",
    "def degree_centralized_distribution(G):\n",
    "    degree = [d[1] for d in G.degree()]\n",
    "    plt.bar(G.nodes(), np.divide(degree , (len(G.nodes()) - 1)))\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Degree Centralised Distribution')\n",
    "    plt.show()\n",
    "    return np.divide(degree , (len(G.nodes()) - 1))\n",
    "# degree_centralized_distribution(G)\n",
    "\n",
    "def bfs_shortest_paths(G, source):\n",
    "    visited = {source: 0}\n",
    "    queue = [source]\n",
    "    paths = {node: [] for node in G.nodes}\n",
    "    paths[source] = [[source]]\n",
    "\n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        neighbors = G[current]\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in visited:\n",
    "                visited[neighbor] = visited[current] + 1\n",
    "                queue.append(neighbor)\n",
    "\n",
    "            if visited[neighbor] == visited[current] + 1:\n",
    "                paths[neighbor] += [path + [neighbor] for path in paths[current]]\n",
    "\n",
    "    return paths\n",
    "\n",
    "def betweenness_centrality(G):\n",
    "    shoretest_path_matrix = shortest_path_number(G)\n",
    "    dic = dict(zip(G.nodes(), range(len(G.nodes()))))\n",
    "    Numerator = [np.zeros((len(G.nodes()), len(G.nodes()))) for _ in range(len(G.nodes()))]\n",
    "    for node in G.nodes:\n",
    "        for start in [n for n in G.nodes if n != node]:\n",
    "            for end in [n for n in G.nodes if n != node]:\n",
    "                if start != end:\n",
    "                    # Calculate the number of shortest paths from start to end that pass through node\n",
    "                    shortest_paths = bfs_shortest_paths(G, start)\n",
    "                    count = sum(node in path for path in shortest_paths[end])\n",
    "                    Numerator[dic.get(node)][dic.get(start)][dic.get(end)] += count\n",
    "    \n",
    "    # 将 shoretest_path_matrix 转换为 NumPy 数组\n",
    "    shoretest_path_matrix_np = np.array(shoretest_path_matrix)\n",
    "    # print(Numerator)\n",
    "    Numerator_np = np.array(Numerator)\n",
    "    # 然后计算 result\n",
    "    re = []\n",
    "    mask = shoretest_path_matrix_np != 0\n",
    "    # print(mask)\n",
    "    for i in Numerator_np:\n",
    "        # 创建一个掩码，标识 B 中非零元素的位置\n",
    "        # print(i)\n",
    "        # 初始化一个与 A 相同形状的全零矩阵\n",
    "        result = np.zeros_like(i)\n",
    "\n",
    "        # 只对 B 中非零元素对应的位置进行除法操作\n",
    "        result[mask] = i[mask] / shoretest_path_matrix_np[mask]\n",
    "\n",
    "        re.append(np.sum(result))\n",
    "    # result = shoretest_path_matrix_np[:, :, np.newaxis] / Numerator\n",
    "    re = np.array(re)\n",
    "    \n",
    "    print(\"betweenness_centrality NetworkX:\", nx.betweenness_centrality(G,normalized=True))\n",
    "    # 输出结果\n",
    "    result = dict(zip(G.nodes(), re/((len(G.nodes()) - 1) * (len(G.nodes()) - 2))))\n",
    "    return result\n",
    "    \n",
    "def shortest_path_number(G):\n",
    "    n = G.number_of_nodes()\n",
    "    matrix = [np.zeros((n, n))]\n",
    "    shortest_path_number = np.zeros((n, n))\n",
    "    np.fill_diagonal(shortest_path_number, np.inf)\n",
    "    adj_matrix = np.array(nx.to_numpy_array(G))\n",
    "    matrix = adj_matrix\n",
    "    mask = shortest_path_number != 0\n",
    "    np.fill_diagonal(shortest_path_number, np.inf)\n",
    "    for i in range(1, n):\n",
    "        for p in range(n): \n",
    "            for q in range(n):\n",
    "                if q != p:\n",
    "                    if matrix[p][q] != 0 and shortest_path_number[p][q] == 0:\n",
    "                        shortest_path_number[p][q] = matrix[p][q]\n",
    "        matrix = matrix @ adj_matrix\n",
    "        # print(matrix)\n",
    "    # 将对角线上的值设置为0，因为节点到自身的距离为0\n",
    "    np.fill_diagonal(shortest_path_number, 0)\n",
    "    return shortest_path_number\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
